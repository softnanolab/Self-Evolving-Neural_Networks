{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Self Evolving Neural Networks_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJUM6skoUekqgdZelIanGW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cosmo571/Self_evolving_nn/blob/main/Self_Evolving_Neural_Networks_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep:\n",
        "\n",
        "\n",
        " Main functions: - algorithm\n",
        "\n",
        " -function that returns the GC potential\n",
        "\n",
        " -function that evolves the network\n",
        " \n",
        " Helper functions: -function that evolves the network needs a creator function that creates new networks in tensorflow.\n"
      ],
      "metadata": {
        "id": "0-jkFcbJm65S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import product\n",
        "from collections.abc import Iterable"
      ],
      "metadata": {
        "id": "ehljsuYrzzFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions\n",
        "def add_neuron(model: keras.Model, chosen_layer: int) -> \"keras.Model\":\n",
        "  model.layers[chosen_layer].units += 1\n",
        "  n_model = model_from_json(model.to_json())\n",
        "  return n_model\n",
        "def remove_neuron(model: keras.Model, chosen_layer: int) -> \"keras.Model\":\n",
        "  model.layers[chosen_layer].units -= 1\n",
        "  n_model = model_from_json(model.to_json())\n",
        "  return n_model\n",
        "def add_layer(model: keras.Model, position: int, neurons: int) -> \"keras.Model\": \n",
        "  '''\n",
        "  Adds a relu layer to a keras.Sequential model. \n",
        "  Note: The implementation is a bit hacky and I am not satisfied with it. Try to come up with other solutions\n",
        "  '''\n",
        "  layer_list = [layr.units for layr in model.layers]\n",
        "  #take the TensorFlow dimension, flips it, removes the None values, changes it into a tuple. This is done as in not to result in a multiple output shapes error (underdefined model)\n",
        "  input = tuple(filter(lambda item: item is not None, np.flip(model.input.shape)))\n",
        "  last_layer = layers.Dense(1, activation='sigmoid') # This is optimised for binary classification problems\n",
        "  layer_list.insert(position, neurons)\n",
        "  layer_list.pop()\n",
        "  n_model = keras.Sequential()\n",
        "  n_model.add(layers.Input(shape=input))\n",
        "  for neur in layer_list:\n",
        "    n_model.add(layers.Dense(units=neur, activation='relu'))\n",
        "  n_model.add(last_layer)\n",
        "  return n_model\n",
        "def remove_layer(model: keras.Model, position: int) -> \"keras.Model\":\n",
        "  '''\n",
        "  Removes a layer in a similar fashion to add_layer()\n",
        "  '''\n",
        "  layer_list = [layr.units for layr in model.layers]\n",
        "  #take the TensorFlow dimension, flips it, removes the None values, changes it into a tuple. This is done as in not to result in a multiple output shapes error (underdefined model)\n",
        "  input = tuple(filter(lambda item: item is not None, np.flip(model.input.shape)))\n",
        "  last_layer = layers.Dense(1, activation='sigmoid') # This is optimised for binary classification problems\n",
        "  layer_list.pop(position)\n",
        "  layer_list.pop()\n",
        "  n_model = keras.Sequential()\n",
        "  n_model.add(layers.Input(shape=input))\n",
        "  for layr in layer_list:\n",
        "    n_model.add(layers.Dense(units=layr, activation='relu'))\n",
        "  n_model.add(last_layer)\n",
        "  return n_model  \n",
        "def remove_layer_experimental(model: keras.Model, position: int, neurons: int) -> \"keras.Model\":\n",
        "  '''\n",
        "  I like this version of remove layer more. It's more versatile. However, I can see it causing plenty of bugs.\n",
        "  '''\n",
        "  layer_list = model.layers\n",
        "  #take the TensorFlow dimension, flips it, removes the None values, changes it into a tuple. This is done as in not to result in a multiple output shapes error (underdefined model)\n",
        "  input = tuple(filter(lambda item: item is not None, np.flip(model.input.shape)))\n",
        "  layer_list.pop(position)\n",
        "  n_model = keras.Sequential()\n",
        "  n_model.add(layers.Input(shape=input))\n",
        "  for layer in layer_list:\n",
        "    n_model.add(layer)\n",
        "  return n_model\n",
        "def calculate_neuron_acceptance_probability( NN:float, energy_N:float, energy_N_1, beta:float , nu:float) -> \"float\":\n",
        "  coeff = 1/(NN+1)\n",
        "  z = np.exp(-beta*nu)\n",
        "  exponent  = np.exp(-beta*(energy_N_1-energy_N))\n",
        "  probability = coeff * exponent * z\n",
        "  if(probability > 1):\n",
        "    probability = 1\n",
        "  return probability \n",
        "def calculate_neuron_removal_probability(NN:float, energy_N:float, energy_N_1, beta:float , nu:float) -> \"float\":\n",
        "  coeff = NN\n",
        "  inverse_z = np.exp(beta*nu)\n",
        "  exponent  = np.exp(-beta*(energy_N-energy_N_1))\n",
        "  probability = coeff * exponent * inverse_z\n",
        "  if(probability > 1):\n",
        "    probability = 1\n",
        "  return probability \n",
        "def calculate_layer_acceptance_probability(NL: float, M:float, energy_NL:float, energy_NL_1, beta:float , nu:float) -> \"float\":\n",
        "  coeff = (NL+M) / (NL+1)\n",
        "  z = np.exp(-beta*nu*M)\n",
        "  exponent = np.exp(-beta*(energy_NL_1-energy_NL))\n",
        "  probability = coeff * exponent * z\n",
        "  if(probability > 1):\n",
        "    probability = 1\n",
        "  return probability\n",
        "def calculate_layer_removal_probability(NL: float, M:float, energy_NL:float, energy_NL_1, beta:float , nu:float) -> \"float\":\n",
        "  coeff = NL / (M*(NL-1))\n",
        "  inverse_z = np.exp(beta*nu*M)\n",
        "  exponent = np.exp(-beta*(energy_NL-energy_NL_1))\n",
        "  probability = coeff * exponent * inverse_z\n",
        "  if(probability > 1):\n",
        "    probability = 1\n",
        "  return probability\n",
        "def construct_model_binary_classification(input_shape: tuple, layer_list) -> \"keras.Model\":\n",
        "  '''\n",
        "  Adapt the last layer to anything\n",
        "  '''\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "  for neurons in layer_list: \n",
        "    model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "  model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "4bK-60k2m6IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run simulation functions\n",
        "# Unstable - doesn't work for some reason. I'll look more into it. initially I had iterables (x_train, y_train) as : Interable in annotations. Still doesn't work\n",
        "# Always run the next cell instead\n",
        "def save_model(model: keras.Model) -> \"None\":\n",
        "  '''\n",
        "  Saves model in the filepath stated in the initial name declaration. \n",
        "  The naming rule is: layer_neurons.nextLayer_nextLayerNeurons\n",
        "  '''\n",
        "  name=\"/Projects/models_sim_date/\"\n",
        "  for i in range(len(model.layers)):\n",
        "    name += \"l_\" + str(i+1) + \"_n_\" +str(model.layers[i].units)\n",
        "    name += \".\"\n",
        "  #name += \"t_\" + str(time.time()) Removed at the moment to shorten the filenames\n",
        "  model.save(name)\n",
        "  print('saved ' + name + \"/\")\n",
        "  return\n",
        "def run_model(model: keras.Model, x_train, y_train, x_test, y_test) -> \"float\":\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
        "  model.fit(x_train, y_train, epochs=5, batch_size=5,verbose=0)\n",
        "  loss , mae = model.evaluate(x_test, y_test)\n",
        "  return loss\n",
        "\n",
        "def run_sim_neuron(model: keras.Model, loss: float, x_train, y_train, x_test, y_test, beta: float, nu: float) -> \"keras.Model\":\n",
        "  '''\n",
        "  function that runs move 1. loss was the term chosen for the energy of the system before the move, energy was chosen for the energy fo the system after the move.\n",
        "  even if they are technically the same in terms of units (both losses/energy)\n",
        "  this was chosen to avoid confusion between the two\n",
        "  '''\n",
        "  #brute force functions to solve the neuron removal problem until I ask stefano\n",
        "  check_neurons_list = [lay.units <= 1 for lay in model.layers[1:-1]]\n",
        "  if all(check_neurons_list) == True:\n",
        "    return model\n",
        "  while True: \n",
        "    layer = np.random.randint(low=1, high=len(model.layers)-1)\n",
        "    NN = model.layers[layer].units\n",
        "    if NN > 1: \n",
        "      break\n",
        "  #END BRUTE FORCE\n",
        "  add_neuron_prob = np.random.choice([True, False])\n",
        "  if add_neuron_prob == True: \n",
        "    new_model = add_neuron(model, layer)\n",
        "  else:\n",
        "    new_model = remove_neuron(model, layer)\n",
        "  #calculate model loss \n",
        "  energy = run_model(new_model, x_train, y_train, x_test, y_test)\n",
        "  #run acceptance\n",
        "  if(add_neuron_prob == True):\n",
        "    probability = calculate_neuron_acceptance_probability(NN, loss, energy, beta, nu)\n",
        "  else:\n",
        "    probability = calculate_neuron_removal_probability(NN-1, energy, loss, beta, nu)\n",
        "    # it is assumed that for this NN+1(i) is the model before the operation, and NN(i) is the model after the operation, hence the NN-1, and the reversed orders of energy and loss.\n",
        "  if np.random.rand() < probability:\n",
        "    print('model saved '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    #just for trial, we save every model we ever make for this time\n",
        "    save_model(new_model)\n",
        "    return new_model\n",
        "  else:\n",
        "    print('model failed '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    return model\n",
        "\n",
        "def run_sim_layer(model: keras.Model, loss: float, x_train, y_train, x_test, y_test, beta: float, nu: float) -> \"keras.Model\":\n",
        "  '''\n",
        "  function that runs move 1. loss was the term chosen for the energy of the system before the move, energy was chosen for the energy fo the system after the move.\n",
        "  even if they are technically the same in terms of units (both losses/energy)\n",
        "  this was chosen to avoid confusion between the two\n",
        "  '''\n",
        "  neurons = np.random.randint(low=1, high=M)\n",
        "  add_layer_prob = np.random.choice([True, False])\n",
        "  if add_layer_prob == True: \n",
        "    layer = np.random.randint(low=1, high=len(model.layers)-1)\n",
        "    new_model = add_layer(model, layer, neurons)\n",
        "  else:\n",
        "    #brute force way\n",
        "    if(len(model.layers)-2 <= 1):\n",
        "      return model\n",
        "    layer = np.random.randint(low=1, high=len(model.layers)-2)\n",
        "    new_model = remove_layer(model, layer)\n",
        "  #calculate model loss \n",
        "  NL = len(new_model.layers)\n",
        "  energy = run_model(new_model, x_train, y_train, x_test, y_test)\n",
        "  #run acceptance\n",
        "  if(add_layer_prob == True):\n",
        "    probability = calculate_layer_acceptance_probability(NL, neurons, loss, energy, beta, nu)\n",
        "  else:\n",
        "    probability = calculate_layer_removal_probability(NL, M, energy, loss, beta, nu)\n",
        "    # it is assumed that for this NN+1(i) is the model before the operation, and NN(i) is the model after the operation, hence the NN-1, and the reversed orders of energy and loss.\n",
        "  if np.random.rand() < probability:\n",
        "    print('model saved '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    #just for trial, we save every model we ever make for this time\n",
        "    save_model(new_model)\n",
        "    return new_model\n",
        "  else:\n",
        "    print('model failed '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    return model\n",
        "\n",
        "def run_sim_step(model: keras.Model, x_train, y_train, x_test, y_test, f: float, beta: float, nu: float, M: int) -> \"keras.Model\":\n",
        "  print('check step')\n",
        "  loss = run_model(model, x_train, y_train, x_test, y_test)\n",
        "  print('loss is checked')\n",
        "  if np.random.rand() < f:\n",
        "    print('start neuron')\n",
        "    model = run_sim_neuron(model, loss, x_train, y_train, x_test, y_test, beta, nu)\n",
        "    print('check step neuron')\n",
        "  else:\n",
        "    print('start layer')\n",
        "    model = run_sim_layer(model, loss, x_train, y_train, x_test, y_test, beta, nu, M)\n",
        "    print('check step layer')\n",
        "  return model \n",
        "\n",
        "def run_sim_for_loop(x_train, y_train, x_test, y_test, f: float, beta: float, nu: float, M: int, number_of_starting_layers: int, low_neuron: int, high_neuron: int, iterations: int) -> keras.Model:\n",
        "  print('check loop')\n",
        "  model_layers = np.random.randint(low=low_neuron, high=high_neuron, size=number_of_starting_layers)\n",
        "  model = construct_model_binary_classification(x_train.shape, model_layers)\n",
        "  loss = run_model(model, x_train, y_train, x_test, y_test)\n",
        "  for i in range(iterations):\n",
        "    model = run_sim_step(model, x_train, y_train, x_test, y_test, f, beta, nu, M)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "5xecdAZy4yIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run simulation functions\n",
        "def save_model(model):\n",
        "  name=\"/Projects/models_sim_0_21.08.2022/\"\n",
        "  for i in range(len(model.layers)):\n",
        "    name += \"l_\" + str(i) + \"_n_\" +str(model.layers[i].units)\n",
        "    name += \"__\"\n",
        "  #name += \"t_\" + str(time.time())\n",
        "  model.save(name)\n",
        "  print('saved ' + name + \"/\")\n",
        "  return\n",
        "def run_model(model, x_train, y_train, x_test, y_test):\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
        "  model.fit(x_train, y_train, epochs=5, batch_size=5,verbose=0)\n",
        "  loss , mae = model.evaluate(x_test, y_test)\n",
        "  return loss\n",
        "\n",
        "def run_sim_neuron(model, loss, x_train, y_train, x_test, y_test, beta, nu):\n",
        "  '''\n",
        "  function that runs move 1. loss was the term chosen for the energy of the system before the move, energy was chosen for the energy fo the system after the move.\n",
        "  even if they are technically the same in terms of units (both losses/energy)\n",
        "  this was chosen to avoid confusion between the two\n",
        "  '''\n",
        "  #brute force functions to solve the neuron removal problem until I ask stefano\n",
        "  check_neurons_list = [lay.units <= 1 for lay in model.layers[1:-1]]\n",
        "  if all(check_neurons_list) == True:\n",
        "    return model\n",
        "  while True: \n",
        "    layer = np.random.randint(low=1, high=len(model.layers)-1)\n",
        "    NN = model.layers[layer].units\n",
        "    if NN > 1: \n",
        "      break\n",
        "  #END BRUTE FORCE\n",
        "  add_neuron_prob = np.random.choice([True, False])\n",
        "  if add_neuron_prob == True: \n",
        "    new_model = add_neuron(model, layer)\n",
        "  else:\n",
        "    new_model = remove_neuron(model, layer)\n",
        "  #calculate model loss \n",
        "  energy = run_model(new_model, x_train, y_train, x_test, y_test)\n",
        "  #run acceptance\n",
        "  if(add_neuron_prob == True):\n",
        "    probability = calculate_neuron_acceptance_probability(NN, loss, energy, beta, nu)\n",
        "  else:\n",
        "    probability = calculate_neuron_removal_probability(NN-1, energy, loss, beta, nu)\n",
        "    # it is assumed that for this NN+1(i) is the model before the operation, and NN(i) is the model after the operation, hence the NN-1, and the reversed orders of energy and loss.\n",
        "  if np.random.rand() < probability:\n",
        "    print('model saved '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    #just for trial, we save every model we ever make for this time\n",
        "    save_model(new_model)\n",
        "    return new_model\n",
        "  else:\n",
        "    print('model failed '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    return model\n",
        "  #just to be sure\n",
        "  #return model\n",
        "\n",
        "def run_sim_layer(model, loss, x_train, y_train, x_test, y_test, beta, nu, M):\n",
        "  '''\n",
        "  function that runs move 1. loss was the term chosen for the energy of the system before the move, energy was chosen for the energy fo the system after the move.\n",
        "  even if they are technically the same in terms of units (both losses/energy)\n",
        "  this was chosen to avoid confusion between the two\n",
        "  '''\n",
        "  neurons = np.random.randint(low=1, high=M)\n",
        "  add_layer_prob = np.random.choice([True, False])\n",
        "  if add_layer_prob == True: \n",
        "    layer = np.random.randint(low=1, high=len(model.layers)-1)\n",
        "    new_model = add_layer(model, layer, neurons)\n",
        "  else:\n",
        "    #brute force way\n",
        "    if(len(model.layers)-2 <= 1):\n",
        "      return model\n",
        "    layer = np.random.randint(low=1, high=len(model.layers)-2)\n",
        "    new_model = remove_layer(model, layer)\n",
        "  #calculate model loss \n",
        "  NL = len(new_model.layers)\n",
        "  energy = run_model(new_model, x_train, y_train, x_test, y_test)\n",
        "  #run acceptance\n",
        "  if(add_layer_prob == True):\n",
        "    probability = calculate_layer_acceptance_probability(NL, neurons, loss, energy, beta, nu)\n",
        "  else:\n",
        "    probability = calculate_layer_removal_probability(NL, M, energy, loss, beta, nu)\n",
        "    # it is assumed that for this NN+1(i) is the model before the operation, and NN(i) is the model after the operation, hence the NN-1, and the reversed orders of energy and loss.\n",
        "  if np.random.rand() < probability:\n",
        "    print('model saved '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    #just for trial, we save every model we ever make for this time\n",
        "    save_model(new_model)\n",
        "    return new_model\n",
        "  else:\n",
        "    print('model failed '+ str(probability) + \" \" + str(loss) + \" \" + str(energy))\n",
        "    return model\n",
        "  #just to be sure\n",
        "  #return model\n",
        "\n",
        "def run_sim_step(model, x_train, y_train, x_test, y_test, f, beta, nu, M):\n",
        "  print('check step')\n",
        "  loss = run_model(model, x_train, y_train, x_test, y_test)\n",
        "  print('loss is checked')\n",
        "  if np.random.rand() < f:\n",
        "    print('start neuron')\n",
        "    model = run_sim_neuron(model, loss, x_train, y_train, x_test, y_test, beta, nu)\n",
        "    print('check step neuron')\n",
        "  else:\n",
        "    print('start layer')\n",
        "    model = run_sim_layer(model, loss, x_train, y_train, x_test, y_test, beta, nu, M)\n",
        "    print('check step layer')\n",
        "  return model \n",
        "\n",
        "def run_sim_for_loop(x_train, y_train, x_test, y_test, f, beta, nu, M, number_of_starting_layers, low_neuron, high_neuron, iterations):\n",
        "  print('check loop')\n",
        "  model_layers = np.random.randint(low=low_neuron, high=high_neuron, size=number_of_starting_layers)\n",
        "  model = construct_model_binary_classification(x_train.shape[1], model_layers)\n",
        "  loss = run_model(model, x_train, y_train, x_test, y_test)\n",
        "  for i in range(iterations):\n",
        "    model = run_sim_step(model, x_train, y_train, x_test, y_test, f, beta, nu, M)\n",
        "  return model"
      ],
      "metadata": {
        "id": "BLMBmQb5spH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply here\n",
        "x, y = datasets.make_moons(n_samples=1000, shuffle=True, noise=0.2, random_state=None)\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(x, y, test_size = 0.2)\n",
        "x_test, y_test = datasets.make_moons(n_samples=250, shuffle=True, noise=0.2, random_state=None)\n",
        "mode = run_sim_for_loop(x_train, y_train, x_dev, y_dev, 0.7, 52, 0.01, 4, 3, 2, 8, 50)\n",
        "mode.summary()\n",
        "loss, mae = mode.evaluate(x_test, y_test)\n",
        "print(loss, mae)"
      ],
      "metadata": {
        "id": "MHb6cAeWYVzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd182e5-8eb2-4b87-ed2d-2199559a8d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check loop\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9450\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.4400\n",
            "model failed 7.43167719289305e-15 0.09821504354476929 0.699382483959198\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8850\n",
            "model failed 7.229016536030759e-06 0.09011543542146683 0.27330097556114197\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9550\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6971 - accuracy: 0.4400\n",
            "model failed 5.05922420692731e-15 0.11152983456850052 0.6971385478973389\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9250\n",
            "model failed 0.019388486505826506 0.08088766783475876 0.20117296278476715\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9650\n",
            "model saved 0.904307816419164 0.09646435081958771 0.13934941589832306\n",
            "saved /Projects/models_sim_0_21.08.2022/l_0_n_4__l_1_n_5__l_2_n_3__l_3_n_1__/\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.9300\n",
            "model failed 5.883835138417493e-05 0.09328091889619827 0.24394288659095764\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9600\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9700\n",
            "model failed 0.06847548113691598 0.1085062101483345 0.11561236530542374\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8650\n",
            "model failed 0.0003475213149026718 0.0934404581785202 0.2875581979751587\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9600\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.8700\n",
            "model failed 0.0011733218774925838 0.10320255160331726 0.26409733295440674\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9450\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3107 - accuracy: 0.8700\n",
            "model failed 0.0001195879938868629 0.11591541022062302 0.31073519587516785\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8750\n",
            "model failed 0.00019725864186744698 0.08894436806440353 0.2896614670753479\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9550\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8650\n",
            "model failed 7.022456106282223e-05 0.11285080015659332 0.32789742946624756\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.4400\n",
            "model failed 2.221032183230677e-15 0.08733838051557541 0.6995404958724976\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8750\n",
            "model failed 0.0005548573360856135 0.08917935192584991 0.2644757330417633\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9600\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9400\n",
            "model failed 0.180342974976675 0.12264708429574966 0.17672526836395264\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.8700\n",
            "model failed 4.74686552729429e-05 0.08699601888656616 0.24178729951381683\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9600\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9150\n",
            "model failed 0.002277218699219363 0.09144776314496994 0.22960105538368225\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8650\n",
            "model failed 9.87546211054758e-05 0.08284983038902283 0.2835425138473511\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9600\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8850\n",
            "model failed 0.0002221332608975967 0.09272073954343796 0.2756323516368866\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8500\n",
            "model failed 9.103158957336142e-06 0.08970814943313599 0.33405545353889465\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9600\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9300\n",
            "model failed 0.022117039101577255 0.10490159690380096 0.19933578372001648\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.8850\n",
            "model failed 4.568688447097294e-05 0.08137434720993042 0.2835608720779419\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.4400\n",
            "model failed 1.720919785393714e-15 0.0866895467042923 0.6995064616203308\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9600\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8750\n",
            "model failed 4.790523934641969e-06 0.10127952694892883 0.3123670816421509\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8400\n",
            "model failed 7.705024630578096e-08 0.0884159654378891 0.3589361310005188\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8400\n",
            "model failed 1.9613618448534487e-05 0.08839236944913864 0.3179780840873718\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9550\n",
            "model failed 0.11597897616182531 0.07974892854690552 0.1423165649175644\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9450\n",
            "model failed 0.08220317163549047 0.08668521046638489 0.17568519711494446\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8900\n",
            "model failed 0.0002621617272110441 0.08386287838220596 0.2791098654270172\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4400\n",
            "model failed 2.0044163929307315e-13 0.10172461718320847 0.6951258778572083\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9550\n",
            "model failed 0.005486661952032516 0.09090286493301392 0.15434788167476654\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.4400\n",
            "model failed 3.755611248046601e-15 0.08279024809598923 0.6970826983451843\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.4400\n",
            "model failed 6.364267388205284e-14 0.08147133141756058 0.6969348788261414\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.8750\n",
            "model failed 0.0002378285502389961 0.08657757937908173 0.26817625761032104\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8450\n",
            "model failed 3.0952125657398204e-06 0.10444279760122299 0.33839768171310425\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.8750\n",
            "model failed 0.00034485828285054585 0.09286162257194519 0.26731446385383606\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9550\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.4400\n",
            "model failed 7.125157882880509e-14 0.09564890712499619 0.7011432647705078\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4400\n",
            "model failed 1.866343383851781e-14 0.08162941038608551 0.6995565295219421\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9000\n",
            "model failed 0.00043765140303736986 0.0937412828207016 0.2254381775856018\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9450\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.4400\n",
            "model failed 3.736533362092006e-13 0.12545090913772583 0.696885883808136\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9750\n",
            "loss is checked\n",
            "start layer\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8900\n",
            "model failed 0.0001652108762212268 0.08498270064592361 0.2735876739025116\n",
            "check step layer\n",
            "check step\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9700\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "check step\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9650\n",
            "loss is checked\n",
            "start neuron\n",
            "check step neuron\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_91 (Dense)            (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 5)                 25        \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59\n",
            "Trainable params: 59\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9720\n",
            "0.0654880478978157 0.972000002861023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1IckHi925uH",
        "outputId": "ab1ef808-816c-4a65-b023-8140238d07b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "fatal: remote origin already exists.\n"
          ]
        }
      ]
    }
  ]
}